cc_unstrat$case_weights <- weighted_param(cc_unstrat$time, cc_unstrat$status,
design    = "casecohort",
subcohort = cc_unstrat$subco)
cc_unstrat_an <- cc_unstrat %>% filter(subco | status == 1)
fit_cox_prentice <- coxph(
Surv(time, status) ~ age + sex + biomarker,
data    = cc_unstrat_an,
weights = case_weights,         # Prentice sampling weights
x = T, y = T
)
pam.coxph_restricted(fit_cox_prentice, predict = T) -> pred.results
pam.predicted_survial_eval_two_phase(analysis_data = cc_unstrat_an, pred_results = pred.results, eval_time = eval_time, km_cens_fit = km_cens, case_weights = cc_unstrat_an$case_weights, metrics = c("Harrell’s C", "Uno’s C", "Brier Score", "Time Dependent Auc"))
### (b) Stratified case-cohort (Borgan II) ------------------------------
# stratum = sex × above/below median age
age_med <- median(cohort$age, na.rm = TRUE)
cohort  <- cohort %>%
mutate(strata = interaction(sex, age > age_med, drop = TRUE))
# Allocate sub-cohort proportionally to cases in each stratum
cases_per_stratum <- table(cohort$strata[cohort$status == 1])
p_stratum         <- cases_per_stratum / sum(cases_per_stratum)
subco_strat <- unlist(Map(
function(st, p)
sample(cohort$id[cohort$strata == st], round(p * nrow(cohort) * subco_size)),
st = names(p_stratum), p = p_stratum
))
cc_strat <- cohort %>%
mutate(subco = id %in% subco_strat,
case  = status == 1)
cc_strat$case_weights <- pam.weighted_param(cc_strat$time, cc_strat$status,
design     = "strat_casecohort",
strata     = cc_strat$strata,
subcohort  = cc_strat$subco)
### (b) Stratified case-cohort (Borgan II) ------------------------------
# stratum = sex × above/below median age
age_med <- median(cohort$age, na.rm = TRUE)
cohort  <- cohort %>%
mutate(strata = interaction(sex, age > age_med, drop = TRUE))
# Allocate sub-cohort proportionally to cases in each stratum
cases_per_stratum <- table(cohort$strata[cohort$status == 1])
p_stratum         <- cases_per_stratum / sum(cases_per_stratum)
subco_strat <- unlist(Map(
function(st, p)
sample(cohort$id[cohort$strata == st], round(p * nrow(cohort) * subco_size)),
st = names(p_stratum), p = p_stratum
))
cc_strat <- cohort %>%
mutate(subco = id %in% subco_strat,
case  = status == 1)
cc_strat$case_weights <- weighted_param(cc_strat$time, cc_strat$status,
design     = "strat_casecohort",
strata     = cc_strat$strata,
subcohort  = cc_strat$subco)
cc_strat_an <- cc_strat %>% filter(subco | status == 1)
#strata_levels <- levels(cc_strat$strata)
fit_borganII_cox <- coxph(
Surv(time, status) ~ age + sex + biomarker,
data    = cc_strat_an,
weights = case_weights,          # Borgan II sampling weights
x = T, y = T
)
pam.coxph_restricted(fit_borganII_cox, prob = T) -> pred.results
### (b) Stratified case-cohort (Borgan II) ------------------------------
# stratum = sex × above/below median age
age_med <- median(cohort$age, na.rm = TRUE)
cohort  <- cohort %>%
mutate(strata = interaction(sex, age > age_med, drop = TRUE))
# Allocate sub-cohort proportionally to cases in each stratum
cases_per_stratum <- table(cohort$strata[cohort$status == 1])
p_stratum         <- cases_per_stratum / sum(cases_per_stratum)
subco_strat <- unlist(Map(
function(st, p)
sample(cohort$id[cohort$strata == st], round(p * nrow(cohort) * subco_size)),
st = names(p_stratum), p = p_stratum
))
cc_strat <- cohort %>%
mutate(subco = id %in% subco_strat,
case  = status == 1)
cc_strat$case_weights <- weighted_param(cc_strat$time, cc_strat$status,
design     = "strat_casecohort",
strata     = cc_strat$strata,
subcohort  = cc_strat$subco)
cc_strat_an <- cc_strat %>% filter(subco | status == 1)
#strata_levels <- levels(cc_strat$strata)
fit_borganII_cox <- coxph(
Surv(time, status) ~ age + sex + biomarker,
data    = cc_strat_an,
weights = case_weights,          # Borgan II sampling weights
x = T, y = T
)
pam.coxph_restricted(fit_borganII_cox, predict = T) -> pred.results
## ---------- evaluate  -----------------------------------
pam.predicted_survial_eval_two_phase(analysis_data = cc_unstrat_an, pred_results = pred.results, eval_time = eval_time, km_cens_fit = km_cens, case_weights = cc_unstrat_an$case_weights, metrics = c("Harrell’s C", "Uno’s C", "Brier Score", "Time Dependent Auc"))
evaluate_cch_performance <- function(analysis_data, pred_results, eval_time, km_cens_fit, case_weights, metrics = c("Harrell’s C", "Uno’s C", "Brier Score", "Time Dependent Auc")) {
# --- Prepare data for evaluation metrics ---
# This step adds the necessary columns for the yardstick functions
# The original mutate call is split into two to prevent the "object not found" error.
# First, create the base columns including 'pred'.
dat1_intermediate <- analysis_data %>%
mutate(
surv_obj = Surv(time, status),
# Extract the survival probability at the specific evaluation time
pred = pred_results$surv_prob[max(which(pred_results$time <= eval_time)), ],
pred.t = pred_results$pred,
case_weights = case_weights,
# Determine the time for IPCW calculation based on event status and time
weight_time = case_when(
status == 1 & time <= eval_time ~ pmax(time, 0), # Category 1: Events before eval_time
time > eval_time              ~ eval_time,    # Category 2: Censored after eval_time
TRUE                          ~ NA_real_      # Category 3: Events after eval_time (no weight)
)
)
# Now, create the nested '.pred' column using the columns from the step above.
dat1 <- dat1_intermediate %>%
mutate(
.pred = map2(
pred, weight_time,
~ tibble(
.eval_time = eval_time,
.pred_survival = .x,
# Calculate Inverse Probability of Censoring Weight (IPCW)
.weight_censored = if (!is.na(.y)) 1 / km_surv(.y, km_cens_fit) else 0
)
)
)
# --- Calculate Performance Metrics ---
# These functions need to be defined in your environment, likely from the 'yardstick'
# or 'censored' package. We assume they are available.
results <- list()
if ("Harrell’s C" %in% metrics) {
c_index <- survival::concordance(
dat1$surv_obj ~ dat1$pred.t,
weights = dat1$case_weights,
)$concordance
results <- append(results, list("Harrell’s C" = c_index))
}
if ("Uno’s C" %in% metrics) {
c_index <- survival::concordance(
dat1$surv_obj ~ dat1$pred.t,
weights = dat1$case_weights,
timewt = "n/G2",
)$concordance
results <- append(results, list("Uno’s C" = c_index))
}
# --- Brier score
if ("Brier Score" %in% metrics) {
brier <- brier_survival(
data         = dat1,
truth        = surv_obj,
.pred,
case_weights = case_weights
)$.estimate
results <- append(results, list("Brier Score" = brier))
}
# --- Time-dependent AUC
if ("Time Dependent Auc" %in% metrics) {
auc <- roc_auc_survival(
data         = dat1,
truth        = surv_obj,
.pred,
case_weights = case_weights
)$.estimate
results <- append(results, list("Time Dependent AUC" = auc))
}
}
performance_results <- evaluate_cch_performance(
analysis_data = cc_unstrat_an,
pred_results = temp,
eval_time = eval_time,
km_cens_fit = km_cens,
case_weights = cc_unstrat_an$w_prentice
)
evaluate_cch_performance <- function(analysis_data, pred_results, eval_time, km_cens_fit, case_weights, metrics = c("Harrell’s C", "Uno’s C", "Brier Score", "Time Dependent Auc")) {
# --- Prepare data for evaluation metrics ---
# This step adds the necessary columns for the yardstick functions
# The original mutate call is split into two to prevent the "object not found" error.
# First, create the base columns including 'pred'.
dat1_intermediate <- analysis_data %>%
mutate(
surv_obj = Surv(time, status),
# Extract the survival probability at the specific evaluation time
pred = pred_results$surv_prob[max(which(pred_results$time <= eval_time)), ],
pred.t = pred_results$pred,
case_weights = case_weights,
# Determine the time for IPCW calculation based on event status and time
weight_time = case_when(
status == 1 & time <= eval_time ~ pmax(time, 0), # Category 1: Events before eval_time
time > eval_time              ~ eval_time,    # Category 2: Censored after eval_time
TRUE                          ~ NA_real_      # Category 3: Events after eval_time (no weight)
)
)
# Now, create the nested '.pred' column using the columns from the step above.
dat1 <- dat1_intermediate %>%
mutate(
.pred = map2(
pred, weight_time,
~ tibble(
.eval_time = eval_time,
.pred_survival = .x,
# Calculate Inverse Probability of Censoring Weight (IPCW)
.weight_censored = if (!is.na(.y)) 1 / km_surv(.y, km_cens_fit) else 0
)
)
)
# --- Calculate Performance Metrics ---
# These functions need to be defined in your environment, likely from the 'yardstick'
# or 'censored' package. We assume they are available.
results <- list()
if ("Harrell’s C" %in% metrics) {
c_index <- survival::concordance(
dat1$surv_obj ~ dat1$pred.t,
weights = dat1$case_weights,
)$concordance
results <- append(results, list("Harrell’s C" = c_index))
}
if ("Uno’s C" %in% metrics) {
c_index <- survival::concordance(
dat1$surv_obj ~ dat1$pred.t,
weights = dat1$case_weights,
timewt = "n/G2",
)$concordance
results <- append(results, list("Uno’s C" = c_index))
}
# --- Brier score
if ("Brier Score" %in% metrics) {
brier <- brier_survival(
data         = dat1,
truth        = surv_obj,
.pred,
case_weights = case_weights
)$.estimate
results <- append(results, list("Brier Score" = brier))
}
# --- Time-dependent AUC
if ("Time Dependent Auc" %in% metrics) {
auc <- roc_auc_survival(
data         = dat1,
truth        = surv_obj,
.pred,
case_weights = case_weights
)$.estimate
results <- append(results, list("Time Dependent AUC" = auc))
}
}
performance_results <- evaluate_cch_performance(
analysis_data = cc_unstrat_an,
pred_results = pred.results,
eval_time = eval_time,
km_cens_fit = km_cens,
case_weights = cc_unstrat_an$w_prentice
)
library(yardstick)
)
performance_results <- evaluate_cch_performance(
analysis_data = cc_unstrat_an,
pred_results = pred.results,
eval_time = eval_time,
km_cens_fit = km_cens,
case_weights = cc_unstrat_an$w_prentice
)
library(dplyr)
performance_results <- evaluate_cch_performance(
analysis_data = cc_unstrat_an,
pred_results = pred.results,
eval_time = eval_time,
km_cens_fit = km_cens,
case_weights = cc_unstrat_an$w_prentice
)
pred.results''
pred.results
cc_unstrat_an$case_weights
rlang::last_trace()
km_surv <- function(t, km_cens) {
if (is.na(t)) return(NA_real_)
summary(km_cens, times = t, extend = TRUE)$surv
}
performance_results <- evaluate_cch_performance(
analysis_data = cc_unstrat_an,
pred_results = pred.results,
eval_time = eval_time,
km_cens_fit = km_cens,
case_weights = cc_unstrat_an$w_prentice
)
performance_results
### (b) Stratified case-cohort (Borgan II) ------------------------------
# stratum = sex × above/below median age
age_med <- median(cohort$age, na.rm = TRUE)
cohort  <- cohort %>%
mutate(strata = interaction(sex, age > age_med, drop = TRUE))
# Allocate sub-cohort proportionally to cases in each stratum
cases_per_stratum <- table(cohort$strata[cohort$status == 1])
p_stratum         <- cases_per_stratum / sum(cases_per_stratum)
subco_strat <- unlist(Map(
function(st, p)
sample(cohort$id[cohort$strata == st], round(p * nrow(cohort) * subco_size)),
st = names(p_stratum), p = p_stratum
))
cc_strat <- cohort %>%
mutate(subco = id %in% subco_strat,
case  = status == 1)
cc_strat$case_weights <- weighted_param(cc_strat$time, cc_strat$status,
design     = "strat_casecohort",
strata     = cc_strat$strata,
subcohort  = cc_strat$subco)
cc_strat_an <- cc_strat %>% filter(subco | status == 1)
#strata_levels <- levels(cc_strat$strata)
fit_borganII_cox <- coxph(
Surv(time, status) ~ age + sex + biomarker,
data    = cc_strat_an,
weights = case_weights,          # Borgan II sampling weights
x = T, y = T
)
pam.coxph_restricted(fit_borganII_cox, predict = T) -> pred.results
## ---------- evaluate  -----------------------------------
pam.predicted_survial_eval_two_phase(analysis_data = cc_unstrat_an, pred_results = pred.results, eval_time = eval_time, km_cens_fit = km_cens, case_weights = cc_unstrat_an$case_weights, metrics = c("Harrell’s C", "Uno’s C", "Brier Score", "Time Dependent Auc"))
pam.predicted_survial_eval_two_phase(analysis_data = cc_unstrat_an, pred_results = pred.results, eval_time = eval_time, km_cens_fit = km_cens, case_weights = cc_unstrat_an$case_weights, metrics = c("Harrell’s C", "Uno’s C", "Brier Score", "Time Dependent Auc"))
### (c) Unmatched nested case-control (2:1) -----------------------------
k <- 2            # number of CONTROLS per case  (2 : 1 design)
eps <- 1e-4       # width of the “fake” entry interval for coxph()
case_rows     <- which(cohort$status == 1)          # rows of all cases
case_ids      <- cohort$id[case_rows]
ctrl_indices  <- integer(0)                         # will collect controls
set_id_vector <- integer(0)                         # parallel vector → set_id
for (idx in case_rows) {
t_fail  <- cohort$time[idx]
riskset <- which(cohort$time >= t_fail & cohort$id != cohort$id[idx])
if (length(riskset) < k) next                     # skip if too few controls
sel <- sample(riskset, k)
ctrl_indices  <- c(ctrl_indices, sel)
set_id_vector <- c(set_id_vector, rep(cohort$id[idx], k))
}
## ---------- build NCC data-frame  ------------------------------------
ncc_unmatch <- bind_rows(
cohort[case_rows, ]           %>% mutate(set_id = id),      # cases
cohort[ctrl_indices, ]        %>% mutate(set_id = set_id_vector) )
# ensure all controls/cases for one set are contiguous (helps readability)
ncc_unmatch <- ncc_unmatch %>% arrange(set_id)
## ---------- compute R_j and w_j  -------------------------------------
ncc_unmatch <- ncc_unmatch %>%               # add R_j per set
group_by(set_id) %>%                       # each set = one case + k ctrls
mutate(R_j = sum(cohort$time >= first(time)),   # first(time) = t_fail of case
k_plus_1 = k + 1,
case_weights = R_j / k_plus_1,
case_time = first(time),
tstart = case_time - eps,
tstop  = case_time)                      # fake interval for coxph()
## fit model
fit_ncc_unmatch <- coxph(Surv(tstart, tstop, status) ~ age + sex + biomarker +
offset(log(w)),
data = ncc_unmatch, x = T, y = T)
### (c) Unmatched nested case-control (2:1) -----------------------------
k <- 2            # number of CONTROLS per case  (2 : 1 design)
eps <- 1e-4       # width of the “fake” entry interval for coxph()
case_rows     <- which(cohort$status == 1)          # rows of all cases
case_ids      <- cohort$id[case_rows]
ctrl_indices  <- integer(0)                         # will collect controls
set_id_vector <- integer(0)                         # parallel vector → set_id
for (idx in case_rows) {
t_fail  <- cohort$time[idx]
riskset <- which(cohort$time >= t_fail & cohort$id != cohort$id[idx])
if (length(riskset) < k) next                     # skip if too few controls
sel <- sample(riskset, k)
ctrl_indices  <- c(ctrl_indices, sel)
set_id_vector <- c(set_id_vector, rep(cohort$id[idx], k))
}
## ---------- build NCC data-frame  ------------------------------------
ncc_unmatch <- bind_rows(
cohort[case_rows, ]           %>% mutate(set_id = id),      # cases
cohort[ctrl_indices, ]        %>% mutate(set_id = set_id_vector) )
# ensure all controls/cases for one set are contiguous (helps readability)
ncc_unmatch <- ncc_unmatch %>% arrange(set_id)
## ---------- compute R_j and w_j  -------------------------------------
ncc_unmatch <- ncc_unmatch %>%               # add R_j per set
group_by(set_id) %>%                       # each set = one case + k ctrls
mutate(R_j = sum(cohort$time >= first(time)),   # first(time) = t_fail of case
k_plus_1 = k + 1,
case_weights = R_j / k_plus_1,
case_time = first(time),
tstart = case_time - eps,
tstop  = case_time)                      # fake interval for coxph()
## fit model
fit_ncc_unmatch <- coxph(Surv(tstart, tstop, status) ~ age + sex + biomarker +
offset(log(case_weights)),
data = ncc_unmatch, x = T, y = T)
pam.coxph_restricted(fit_ncc_unmatch, predict = T) -> pred.results
## ---------- evaluate  -----------------------------------
weighted_param(ncc_unmatch$time, ncc_unmatch$status,
design        = "ncc",
m             = k) -> w
ncc_unmatch <- ncc_unmatch %>% ungroup()
pam.predicted_survial_eval_two_phase(analysis_data = ncc_unmatch, pred_results = pred.results, eval_time = eval_time, km_cens_fit = km_cens, case_weights = ncc_unmatch$case_weights, metrics = c("Harrell’s C", "Uno’s C", "Brier Score", "Time Dependent Auc"))
### (c) Unmatched nested case-control (2:1) -----------------------------
k <- 2            # number of CONTROLS per case  (2 : 1 design)
eps <- 1e-4       # width of the “fake” entry interval for coxph()
case_rows     <- which(cohort$status == 1)          # rows of all cases
case_ids      <- cohort$id[case_rows]
ctrl_indices  <- integer(0)                         # will collect controls
set_id_vector <- integer(0)                         # parallel vector → set_id
for (idx in case_rows) {
t_fail  <- cohort$time[idx]
riskset <- which(cohort$time >= t_fail & cohort$id != cohort$id[idx])
if (length(riskset) < k) next                     # skip if too few controls
sel <- sample(riskset, k)
ctrl_indices  <- c(ctrl_indices, sel)
set_id_vector <- c(set_id_vector, rep(cohort$id[idx], k))
}
## ---------- build NCC data-frame  ------------------------------------
ncc_unmatch <- bind_rows(
cohort[case_rows, ]           %>% mutate(set_id = id),      # cases
cohort[ctrl_indices, ]        %>% mutate(set_id = set_id_vector) )
# ensure all controls/cases for one set are contiguous (helps readability)
ncc_unmatch <- ncc_unmatch %>% arrange(set_id)
## ---------- compute R_j and w_j  -------------------------------------
ncc_unmatch <- ncc_unmatch %>%               # add R_j per set
group_by(set_id) %>%                       # each set = one case + k ctrls
mutate(R_j = sum(cohort$time >= first(time)),   # first(time) = t_fail of case
k_plus_1 = k + 1,
w = R_j / k_plus_1,
case_time = first(time),
tstart = case_time - eps,
tstop  = case_time)                      # fake interval for coxph()
## fit model
fit_ncc_unmatch <- coxph(Surv(tstart, tstop, status) ~ age + sex + biomarker +
offset(log(w)),
data = ncc_unmatch, x = T, y = T)
pam.coxph_restricted(fit_ncc_unmatch, predict = T) -> pred.results
## ---------- evaluate  -----------------------------------
ncc_unmatch$case_weights <- weighted_param(ncc_unmatch$time, ncc_unmatch$status,
design        = "ncc",
m             = k)
ncc_unmatch <- ncc_unmatch %>% ungroup()
pam.predicted_survial_eval_two_phase(analysis_data = ncc_unmatch, pred_results = pred.results, eval_time = eval_time, km_cens_fit = km_cens, case_weights = ncc_unmatch$case_weights, metrics = c("Harrell’s C", "Uno’s C", "Brier Score", "Time Dependent Auc"))
## ─────────────────────────────────────────────────────────────
## (d)  2 : 1  SEX-MATCHED nested case-control sample
## ─────────────────────────────────────────────────────────────
k   <- 2          # controls per case
eps <- 1e-4       # fake-interval width  ( > 0 )
case_rows  <- which(cohort$status == 1)      # indices of all cases
ctrl_idx   <- integer()                     # to collect controls
set_vec    <- integer()                     # parallel vector → set_id
for (idx in case_rows) {
t_fail <- cohort$time[idx]
sx     <- cohort$sex[idx]
risk <- which(cohort$time >= t_fail &      # still at risk
cohort$sex  == sx  &         # same sex  (matching var)
cohort$id   != cohort$id[idx])
if (length(risk) < k) next                 # skip if not enough ctrls
sel        <- sample(risk, k)
ctrl_idx   <- c(ctrl_idx, sel)
set_vec    <- c(set_vec, rep(cohort$id[idx], k))
}
## ---------- build NCC data-frame --------------------------------------
ncc_match <- dplyr::bind_rows(
cohort[case_rows, ]  %>%  dplyr::mutate(set_id = id),   # cases
cohort[ctrl_idx,  ] %>%  dplyr::mutate(set_id = set_vec)
) %>%
dplyr::arrange(set_id)
## ---------- risk-set size  R_j  & weight  w_j  ------------------------
ncc_match <- ncc_match %>%
dplyr::group_by(set_id) %>%
dplyr::mutate(
R_j      = sum(cohort$time >= dplyr::first(time) &      # size of
cohort$sex  == dplyr::first(sex)),       # matching stratum
w        = R_j / (k + 1),                               # (k+1 = 3)
case_t   = dplyr::first(time),                          # case’s fail time
tstart   = case_t - eps,                                # fake interval
tstop    = case_t
) %>%
dplyr::ungroup()
## Cox counting-process formulation
fit_match_cox <- coxph(
Surv(tstart, tstop, status) ~ age + biomarker +
strata(set_id) + offset(log(w)),
data = ncc_match, x = T, y = T
)
pam.coxph_restricted(fit_match_cox, predict = T) -> pred.results
## ---------- evaluate  -----------------------------------
ncc_match$case_weights <- weighted_param(ncc_match$time, ncc_match$status,
design = "matched_ncc",
m      = k,
strata = ncc_match$sex) -> w # note here we need to specify the strata
pam.predicted_survial_eval_two_phase(analysis_data = ncc_match, pred_results = pred.results, eval_time = eval_time, km_cens_fit = km_cens, case_weights = ncc_match$case_weights, metrics = c("Harrell’s C", "Uno’s C", "Brier Score", "Time Dependent Auc"))
### (b) Stratified case-cohort (Borgan II) ------------------------------
# stratum = sex × above/below median age
age_med <- median(cohort$age, na.rm = TRUE)
cohort  <- cohort %>%
mutate(strata = interaction(sex, age > age_med, drop = TRUE))
# Allocate sub-cohort proportionally to cases in each stratum
cases_per_stratum <- table(cohort$strata[cohort$status == 1])
p_stratum         <- cases_per_stratum / sum(cases_per_stratum)
subco_strat <- unlist(Map(
function(st, p)
sample(cohort$id[cohort$strata == st], round(p * nrow(cohort) * subco_size)),
st = names(p_stratum), p = p_stratum
))
cc_strat <- cohort %>%
mutate(subco = id %in% subco_strat,
case  = status == 1)
cc_strat$case_weights <- weighted_param(cc_strat$time, cc_strat$status,
design     = "strat_casecohort",
strata     = cc_strat$strata,
subcohort  = cc_strat$subco)
cc_strat_an <- cc_strat %>% filter(subco | status == 1)
#strata_levels <- levels(cc_strat$strata)
fit_borganII_cox <- coxph(
Surv(time, status) ~ age + sex + biomarker,
data    = cc_strat_an,
weights = case_weights,          # Borgan II sampling weights
x = T, y = T
)
pam.coxph_restricted(fit_borganII_cox, predict = T) -> pred.results
## ---------- evaluate  -----------------------------------
pam.predicted_survial_eval_two_phase(analysis_data = cc_strat_an, pred_results = pred.results, eval_time = eval_time, km_cens_fit = km_cens, case_weights = cc_strat_an$case_weights, metrics = c("Harrell’s C", "Uno’s C", "Brier Score", "Time Dependent Auc"))
